from ultralytics import YOLO
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from transformers import CLIPProcessor, CLIPModel
from PIL import Image, ImageEnhance
from werkzeug.utils import secure_filename
import torch
import tempfile
import os
import json
import uuid

# Import h√†m upload t·ª´ file kh√°c
from services.cloudinary_service import upload_to_cloudinary

app = Flask(__name__)
CORS(app)

# ====================================
# üîπ N·∫°p model YOLO
# ====================================
try:
    model = YOLO("runs/detect/train2/weights/best.pt")
    print("‚úÖ Model YOLO ƒë√£ ƒë∆∞·ª£c n·∫°p th√†nh c√¥ng!")
except Exception as e:
    print(f"‚ùå L·ªói khi n·∫°p model YOLO: {e}")
    model = None

# ====================================
# üîπ N·∫°p model CLIP
# ====================================
try:
    clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    clip_model.to(device)
    print("‚úÖ Model CLIP ƒë√£ ƒë∆∞·ª£c n·∫°p th√†nh c√¥ng!")
except Exception as e:
    print(f"‚ùå L·ªói khi n·∫°p model CLIP: {e}")
    clip_model = None

# ====================================
# üîπ √Ånh x·∫° tag YOLO sang ti·∫øng Vi·ªát
# ====================================
YOLO_TAGS_VI = {
    "Nhan": "nh·∫´n",
    "DayChuyen": "d√¢y chuy·ªÅn",
    "VongTay": "v√≤ng tay",
    "BongTai": "b√¥ng tai",
    "MatDayChuyen": "m·∫∑t d√¢y chuy·ªÅn",
    "unknown": "kh√¥ng x√°c ƒë·ªãnh"
}

# ====================================
# üîπ Nh√≥m tag CLIP (chia theo lo·∫°i)
# ====================================
TAG_GROUPS = {
    "ch·∫•t li·ªáu": {
        "v√†ng": "a gold jewelry piece",
        "b·∫°c": "a silver jewelry piece",
    },
    "phong c√°ch": {
        "t·ªëi gi·∫£n": "a minimalist jewelry design",
        "thanh l·ªãch": "an elegant jewelry style",
        "sang tr·ªçng": "a luxurious jewelry piece",
        "c·ªï ƒëi·ªÉn": "a classic jewelry design",
        "hi·ªán ƒë·∫°i": "a modern jewelry style",
        "ƒë√°ng y√™u": "a cute jewelry item",
        "n·ªØ t√≠nh": "a feminine jewelry piece",
        "nam t√≠nh": "a masculine jewelry style",
        "c√° t√≠nh": "a bold jewelry design",
        "ngh·ªá thu·∫≠t": "an artistic jewelry design",
        "ƒë√≠nh ƒë√°": "a gemstone jewelry"
    },
    "d·ªãp s·ª≠ d·ª•ng": {
        "ƒë√°m c∆∞·ªõi": "a wedding jewelry",
        "h·∫πn h√≤": "a date jewelry",
        "d·ª± ti·ªác": "a party jewelry",
        "qu√† t·∫∑ng": "a gift jewelry",
        "h·∫±ng ng√†y": "a daily wear jewelry",
        "sang tr·ªçng": "a formal jewelry",
        "c√¥ng s·ªü": "an office jewelry",
        "du l·ªãch": "a travel jewelry"
    }
}

# ====================================
# üîπ H√†m tƒÉng m√†u cho CLIP
# ====================================
def enhance_image_for_clip(image: Image.Image) -> Image.Image:
    enhancer = ImageEnhance.Color(image)
    return enhancer.enhance(1.3)

# ====================================
# üîπ H√†m sinh tag b·∫±ng CLIP
# ====================================
def generate_clip_tags(image: Image.Image):
    all_best_tags = []
    image = enhance_image_for_clip(image)

    for group_name, tag_dict in TAG_GROUPS.items():
        try:
            vi_texts = list(tag_dict.keys())
            en_prompts = list(tag_dict.values())

            inputs = clip_processor(
                text=en_prompts,
                images=image,
                return_tensors="pt",
                padding=True
            ).to(device)

            with torch.no_grad():
                outputs = clip_model(**inputs)
                probs = outputs.logits_per_image.softmax(dim=1).cpu().numpy()[0]

            best_idx = probs.argmax()
            best_vi = vi_texts[best_idx]
            all_best_tags.append(best_vi)

            print(f"üéØ CLIP ({group_name}): {best_vi} ({probs[best_idx]:.2f})")

        except Exception as e:
            print(f"‚ùå L·ªói sinh tag CLIP cho nh√≥m {group_name}: {e}")

    return all_best_tags


# ====================================
# üîπ API 1: /auto-tag (ch·ªâ ph√¢n t√≠ch, ch∆∞a upload)
# ====================================
@app.route("/auto-tag", methods=["POST"])
def auto_tag():
    if not model or not clip_model:
        return jsonify({"error": "Model ch∆∞a ƒë∆∞·ª£c n·∫°p!"}), 500

    files = request.files.getlist("files")
    if not files:
        return jsonify({"error": "Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c g·ª≠i!"}), 400

    results_all = []

    for file in files:
        if file.filename == "":
            continue

        tmp_name = f"{uuid.uuid4().hex}.jpg"
        tmp_path = os.path.join(tempfile.gettempdir(), tmp_name)
        file.save(tmp_path)

        print(f"\nüîç X·ª≠ l√Ω ·∫£nh: {file.filename}")

        try:
            results = model(tmp_path, conf=0.5)
            names = model.names
            detected_tags = set()
            img = Image.open(tmp_path).convert("RGB")

            for r in results:
                if not r.boxes:
                    continue
                for box in r.boxes:
                    cls_id = int(box.cls)
                    tag_name = names.get(cls_id, "unknown")
                    tag_vi = YOLO_TAGS_VI.get(tag_name, tag_name)
                    detected_tags.add(tag_vi)
                    print(f"‚úÖ YOLO ph√°t hi·ªán: {tag_vi}")

            if not detected_tags:
                detected_tags.add("kh√¥ng ph√°t hi·ªán s·∫£n ph·∫©m")

            # CLIP sinh m√¥ t·∫£
            clip_tags = generate_clip_tags(img)
            detected_tags.update(clip_tags)

            # Kh√¥ng upload ‚Äî ch·ªâ tr·∫£ v·ªÅ path t·∫°m
            results_all.append({
                "filename": file.filename,
                "tags": list(detected_tags),
                "temp_path": tmp_path
            })

        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω {file.filename}: {e}")
            results_all.append({
                "filename": file.filename,
                "tags": ["L·ªói x·ª≠ l√Ω ·∫£nh"],
                "temp_path": None
            })

    return jsonify({"results": results_all})


# ====================================
# üîπ API 2: /upload-cloud (khi nh·∫•n L∆∞u)
# ====================================

if __name__ == "__main__":
    app.run(debug=True, port=5001)
